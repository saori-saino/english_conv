import streamlit as st
import os
import time
from pathlib import Path
# import wave  # PyAudioé–¢é€£ãªã®ã§ä¸è¦
# import pyaudio  # PyAudioã‚’ç„¡åŠ¹åŒ–
# from pydub import AudioSegment  # pyaudioopã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ç„¡åŠ¹åŒ–
# from audiorecorder import audiorecorder  # pyaudioopã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ç„¡åŠ¹åŒ–
import numpy as np
# from scipy.io.wavfile import write  # æœªä½¿ç”¨ã®ãŸã‚ç„¡åŠ¹åŒ–
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain.schema import SystemMessage
from langchain.memory import ConversationSummaryBufferMemory
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
import constants as ct

def record_audio(audio_input_file_path):
    """
    éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆStreamlitæ¨™æº–æ©Ÿèƒ½ä½¿ç”¨ï¼‰
    """
    
    st.subheader("ğŸ¤ éŸ³å£°å…¥åŠ›")
    
    # Streamlitã®æ¨™æº–éŸ³å£°å…¥åŠ›ã‚’ä½¿ç”¨
    audio_bytes = st.audio_input("éŸ³å£°ã‚’éŒ²éŸ³ã—ã¦ãã ã•ã„")
    
    if audio_bytes is not None:
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        with open(audio_input_file_path, "wb") as f:
            f.write(audio_bytes.getvalue())
        
        st.success("éŸ³å£°ãŒæ­£å¸¸ã«éŒ²éŸ³ã•ã‚Œã¾ã—ãŸï¼")
        return True
    else:
        st.info("éŸ³å£°ã‚’éŒ²éŸ³ã—ã¦ãã ã•ã„ã€‚")
        return False

def record_audio_for_shadowing(audio_input_file_path):
    """
    ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°å°‚ç”¨ã®éŸ³å£°å…¥åŠ›ï¼ˆé‡è¤‡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é¿ã‘ã‚‹ï¼‰
    """
    
    st.subheader("ğŸ¯ ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°éŸ³å£°å…¥åŠ›")
    st.info("ğŸ‘† ä¸Šè¨˜ã®å•é¡Œæ–‡éŸ³å£°ã‚’èã„ãŸå¾Œã€åŒã˜å†…å®¹ã‚’è©±ã—ã¦ãã ã•ã„")
    
    # Streamlitã®æ¨™æº–éŸ³å£°å…¥åŠ›ã‚’ä½¿ç”¨
    audio_bytes = st.audio_input("ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ç”¨éŸ³å£°ã‚’éŒ²éŸ³ã—ã¦ãã ã•ã„")
    
    if audio_bytes is not None:
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        with open(audio_input_file_path, "wb") as f:
            f.write(audio_bytes.getvalue())
        
        st.success("âœ… ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°éŸ³å£°ãŒæ­£å¸¸ã«éŒ²éŸ³ã•ã‚Œã¾ã—ãŸï¼")
        return True
    else:
        st.info("ğŸ”´ ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ç”¨ã®éŸ³å£°ã‚’éŒ²éŸ³ã—ã¦ãã ã•ã„ã€‚")
        return False

def transcribe_audio(audio_input_file_path):
    """
    éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    Args:
        audio_input_file_path: éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """

    with open(audio_input_file_path, 'rb') as audio_input_file:
        transcript = st.session_state.openai_obj.audio.transcriptions.create(
            model="whisper-1",
            file=audio_input_file,
            language="en"
        )
    
    # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    os.remove(audio_input_file_path)

    return transcript

def save_to_wav(llm_response_audio, audio_output_file_path):
    """
    éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥mp3ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ï¼ˆpydubä¸ä½¿ç”¨ç‰ˆï¼‰
    Args:
        llm_response_audio: LLMã‹ã‚‰ã®å›ç­”ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        audio_output_file_path: å‡ºåŠ›å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """

    # OpenAIã®TTSã¯mp3å½¢å¼ã§å‡ºåŠ›ã•ã‚Œã‚‹ãŸã‚ã€ç›´æ¥mp3ã¨ã—ã¦ä¿å­˜
    mp3_file_path = audio_output_file_path.replace('.wav', '.mp3')
    
    try:
        with open(mp3_file_path, "wb") as audio_output_file:
            audio_output_file.write(llm_response_audio)
        return mp3_file_path  # å®Ÿéš›ã«ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¿”ã™
    except Exception as e:
        st.error(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise

def play_wav_auto_for_conversation(audio_output_file_path, speed=1.0):
    """
    æ—¥å¸¸è‹±ä¼šè©±ãƒ¢ãƒ¼ãƒ‰å°‚ç”¨ã®éŸ³å£°è‡ªå‹•å†ç”Ÿ
    Args:
        audio_output_file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        speed: å†ç”Ÿé€Ÿåº¦ï¼ˆç¾åœ¨ã¯ç„¡åŠ¹ã€pydubä¸ä½¿ç”¨ã®ãŸã‚ï¼‰
    """
    
    # é€Ÿåº¦å¤‰æ›´æ©Ÿèƒ½ã®æ¡ˆå†…
    if speed != 1.0:
        st.info(f"âš ï¸ éŸ³å£°é€Ÿåº¦å¤‰æ›´æ©Ÿèƒ½ã¯ç¾åœ¨ç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ï¼ˆæŒ‡å®šé€Ÿåº¦: {speed}xï¼‰")
    
    # Streamlitã®éŸ³å£°å†ç”Ÿæ©Ÿèƒ½ã‚’ä½¿ç”¨ï¼ˆè‡ªå‹•å†ç”Ÿã‚’è©¦è¡Œï¼‰
    try:
        with open(audio_output_file_path, 'rb') as audio_file:
            audio_bytes = audio_file.read()
            
            # ã¾ãšè‡ªå‹•å†ç”Ÿã‚’è©¦è¡Œï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã—ã§ã‚·ãƒ³ãƒ—ãƒ«ã«ï¼‰
            if audio_output_file_path.endswith('.mp3'):
                st.audio(audio_bytes, format='audio/mp3', autoplay=True)
            else:
                st.audio(audio_bytes, format='audio/wav', autoplay=True)
            
            # ãƒ–ãƒ©ã‚¦ã‚¶ã§è‡ªå‹•å†ç”ŸãŒç„¡åŠ¹ãªå ´åˆã®è¿½åŠ æƒ…å ±ï¼ˆexpanderå†…ã«æ ¼ç´ï¼‰
            with st.expander("ğŸ”§ éŸ³å£°ãŒèã“ãˆãªã„å ´åˆ"):
                st.markdown("""
                **ãƒ–ãƒ©ã‚¦ã‚¶ã®è‡ªå‹•å†ç”ŸãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™:**
                1. ä¸Šè¨˜ã®éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã§ â–¶ï¸ ãƒœã‚¿ãƒ³ã‚’æ‰‹å‹•ã§ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„
                2. ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§éŸ³å£°è‡ªå‹•å†ç”Ÿã‚’è¨±å¯ã—ã¦ãã ã•ã„
                3. éŸ³é‡è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„
                
                **Chrome/Edge:** è¨­å®š â†’ ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ â†’ ã‚µã‚¤ãƒˆã®è¨­å®š â†’ éŸ³å£°
                **Firefox:** è¨­å®š â†’ ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ â†’ è¨±å¯è¨­å®š â†’ è‡ªå‹•å†ç”Ÿ
                """)
            
    except Exception as e:
        st.error(f"ğŸš¨ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.info("éŸ³å£°ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ãŒã€ãƒ†ã‚­ã‚¹ãƒˆã§ã®å›ç­”ã¯è¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚")
        return
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¯å³åº§ã«å‰Šé™¤ã›ãšã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã¾ã§ä¿æŒ
    # ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¤‡æ•°å›å†ç”Ÿã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ï¼‰

def play_wav(audio_output_file_path, speed=1.0):
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†ç”Ÿï¼ˆæ‰‹å‹•å†ç”Ÿæ¨å¥¨ï¼‰
    Args:
        audio_output_file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        speed: å†ç”Ÿé€Ÿåº¦ï¼ˆç¾åœ¨ã¯ç„¡åŠ¹ã€pydubä¸ä½¿ç”¨ã®ãŸã‚ï¼‰
    """
    
    # é€Ÿåº¦å¤‰æ›´æ©Ÿèƒ½ã®æ¡ˆå†…
    if speed != 1.0:
        st.warning(f"âš ï¸ éŸ³å£°é€Ÿåº¦å¤‰æ›´æ©Ÿèƒ½ã¯ç¾åœ¨ç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ï¼ˆæŒ‡å®šé€Ÿåº¦: {speed}xï¼‰")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ˜ç¢ºãªæ“ä½œæŒ‡ç¤ºã‚’è¡¨ç¤º
    st.success("ğŸµ **å•é¡Œæ–‡ã®éŸ³å£°ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼**")
    st.info("ğŸ‘‡ **ä¸‹ã®éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã§ â–¶ï¸ ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å•é¡Œæ–‡ã‚’èã„ã¦ãã ã•ã„**")
    
    # Streamlitã®éŸ³å£°å†ç”Ÿæ©Ÿèƒ½ã‚’ä½¿ç”¨
    try:
        with open(audio_output_file_path, 'rb') as audio_file:
            audio_bytes = audio_file.read()
            
            # æ‰‹å‹•å†ç”Ÿã®ã¿ï¼ˆautoplay=Falseã«å¤‰æ›´ï¼‰
            if audio_output_file_path.endswith('.mp3'):
                st.audio(audio_bytes, format='audio/mp3', autoplay=False)
            else:
                st.audio(audio_bytes, format='audio/wav', autoplay=False)
            
            # è¿½åŠ ã®æ¡ˆå†…ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            st.markdown("""
            ï¿½ **éŸ³å£°ãŒèã“ãˆãªã„å ´åˆ:**
            - éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã® â–¶ï¸ ãƒœã‚¿ãƒ³ã‚’æ‰‹å‹•ã§ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„
            - ãƒ–ãƒ©ã‚¦ã‚¶ã®éŸ³é‡è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„
            - ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã¾ãŸã¯ãƒ˜ãƒƒãƒ‰ãƒ•ã‚©ãƒ³ã®æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„
            """)
            
    except Exception as e:
        st.error(f"ğŸš¨ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.info("éŸ³å£°ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ãŒã€ãƒ†ã‚­ã‚¹ãƒˆã§ã®å•é¡Œæ–‡ã¯ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™ã€‚")
        return
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¯å³åº§ã«å‰Šé™¤ã›ãšã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã¾ã§ä¿æŒ
    # ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¤‡æ•°å›å†ç”Ÿã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ï¼‰
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆä¸€å®šæ™‚é–“å¾Œï¼‰
    try:
        # å³åº§ã«å‰Šé™¤ã›ãšã€å°‘ã—å¾…ã¤ï¼ˆéŸ³å£°å†ç”Ÿã®ãŸã‚ï¼‰
        # os.remove(audio_output_file_path)  # éŸ³å£°å†ç”Ÿå®Œäº†å¾Œã¾ã§å‰Šé™¤ã‚’å»¶æœŸ
        pass
    except Exception as e:
        st.warning(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def create_chain(system_template):
    """
    LLMã«ã‚ˆã‚‹å›ç­”ç”Ÿæˆç”¨ã®Chainä½œæˆ
    """

    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=system_template),
        MessagesPlaceholder(variable_name="history"),
        HumanMessagePromptTemplate.from_template("{input}")
    ])
    chain = ConversationChain(
        llm=st.session_state.llm,
        memory=st.session_state.memory,
        prompt=prompt
    )

    return chain

def create_problem_and_play_audio():
    """
    å•é¡Œç”Ÿæˆã¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†ç”Ÿï¼ˆãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
    Args:
        chain: å•é¡Œæ–‡ç”Ÿæˆç”¨ã®Chain
        speed: å†ç”Ÿé€Ÿåº¦ï¼ˆ1.0ãŒé€šå¸¸é€Ÿåº¦ã€0.5ã§åŠåˆ†ã®é€Ÿã•ã€2.0ã§å€é€Ÿãªã©ï¼‰
        openai_obj: OpenAIã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """

    # å•é¡Œæ–‡ã‚’ç”Ÿæˆã™ã‚‹Chainã‚’å®Ÿè¡Œã—ã€å•é¡Œæ–‡ã‚’å–å¾—
    problem = st.session_state.chain_create_problem.predict(input="")

    # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    llm_response_audio = st.session_state.openai_obj.audio.speech.create(
        model="tts-1",
        voice="alloy",
        input=problem
    )

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆï¼ˆmp3å½¢å¼ã§ä¿å­˜ï¼‰
    audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.mp3"
    actual_file_path = save_to_wav(llm_response_audio.content, audio_output_file_path)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ä¿å­˜ï¼ˆst.rerun()å¾Œã‚‚æŒç¶šã™ã‚‹ã‚ˆã†ã«ï¼‰
    st.session_state.current_audio_file = actual_file_path
    st.session_state.audio_ready = True

    return problem, llm_response_audio

def create_problem_and_play_audio_for_shadowing():
    """
    ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°å°‚ç”¨ã®å•é¡Œç”Ÿæˆã¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†ç”Ÿ
    """

    # å•é¡Œæ–‡ã‚’ç”Ÿæˆã™ã‚‹Chainã‚’å®Ÿè¡Œã—ã€å•é¡Œæ–‡ã‚’å–å¾—
    problem = st.session_state.chain_create_problem.predict(input="")

    # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    llm_response_audio = st.session_state.openai_obj.audio.speech.create(
        model="tts-1",
        voice="alloy",
        input=problem
    )

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆï¼ˆmp3å½¢å¼ã§ä¿å­˜ï¼‰
    audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.mp3"
    actual_file_path = save_to_wav(llm_response_audio.content, audio_output_file_path)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ä¿å­˜
    st.session_state.current_audio_file = actual_file_path
    
    # ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°å°‚ç”¨ã®éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã‚’è¡¨ç¤º
    display_audio_player_for_shadowing()

    return problem, llm_response_audio

def display_audio_player():
    """
    éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°ï¼ˆst.rerun()å¾Œã‚‚å‘¼ã³å‡ºã—å¯èƒ½ï¼‰
    """
    if hasattr(st.session_state, 'audio_ready') and st.session_state.audio_ready and hasattr(st.session_state, 'current_audio_file'):
        # ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®è¿½åŠ UIè¡¨ç¤º
        st.markdown("### ğŸ“ ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å•é¡Œ")
        st.info("ğŸ§ **éŸ³å£°ã‚’èã„ã¦ã€èã“ãˆãŸå†…å®¹ã‚’æ­£ç¢ºã«å…¥åŠ›ã—ã¦ãã ã•ã„**")
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’
        play_wav(st.session_state.current_audio_file, st.session_state.speed)
        
        # éŸ³å£°è¡¨ç¤ºå¾Œã¯ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆé‡è¤‡è¡¨ç¤ºã‚’é˜²ãï¼‰
        st.session_state.audio_ready = False

def display_audio_player_for_shadowing():
    """
    ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°å°‚ç”¨ã®éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼è¡¨ç¤º
    """
    if hasattr(st.session_state, 'current_audio_file') and st.session_state.current_audio_file:
        # ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ç”¨ã®è¿½åŠ UIè¡¨ç¤º
        st.markdown("### ğŸ¯ ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°å•é¡Œ")
        st.info("ğŸ§ **ã¾ãšéŸ³å£°ã‚’èã„ã¦ã€ãã®å¾ŒåŒã˜å†…å®¹ã‚’è©±ã—ã¦ãã ã•ã„**")
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’ï¼ˆã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ç”¨ã«æœ€é©åŒ–ï¼‰
        play_wav_for_shadowing(st.session_state.current_audio_file, st.session_state.speed)

def play_wav_for_shadowing(audio_output_file_path, speed=1.0):
    """
    ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°å°‚ç”¨ã®éŸ³å£°å†ç”Ÿï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç°¡æ½”ã«ã™ã‚‹ï¼‰
    """
    
    # é€Ÿåº¦å¤‰æ›´æ©Ÿèƒ½ã®æ¡ˆå†…
    if speed != 1.0:
        st.warning(f"âš ï¸ éŸ³å£°é€Ÿåº¦å¤‰æ›´æ©Ÿèƒ½ã¯ç¾åœ¨ç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ï¼ˆæŒ‡å®šé€Ÿåº¦: {speed}xï¼‰")
    
    # ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ç”¨ã®æ“ä½œæŒ‡ç¤º
    st.success("ğŸµ **ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°å•é¡Œæ–‡ã®éŸ³å£°**")
    st.info("ğŸ‘‡ **éŸ³å£°ã‚’èã„ã¦ã‹ã‚‰ã€åŒã˜å†…å®¹ã‚’éŒ²éŸ³ã—ã¦ãã ã•ã„**")
    
    # Streamlitã®éŸ³å£°å†ç”Ÿæ©Ÿèƒ½ã‚’ä½¿ç”¨
    try:
        with open(audio_output_file_path, 'rb') as audio_file:
            audio_bytes = audio_file.read()
            
            # æ‰‹å‹•å†ç”Ÿã®ã¿
            if audio_output_file_path.endswith('.mp3'):
                st.audio(audio_bytes, format='audio/mp3', autoplay=False)
            else:
                st.audio(audio_bytes, format='audio/wav', autoplay=False)
            
    except Exception as e:
        st.error(f"ğŸš¨ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

def create_evaluation():
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã®è©•ä¾¡ç”Ÿæˆ
    """

    llm_response_evaluation = st.session_state.chain_evaluation.predict(input="")

    return llm_response_evaluation

# LangChainä»£æ›¿é–¢æ•°ï¼ˆPydanticäº’æ›æ€§å•é¡Œã®å›é¿ç”¨ï¼‰
def create_simple_openai_client(api_key):
    """
    å˜ç´”ãªOpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆï¼ˆLangChainä»£æ›¿ï¼‰
    """
    from openai import OpenAI
    return OpenAI(api_key=api_key)

def simple_chat_completion(client, messages, model="gpt-4o-mini", temperature=0.5):
    """
    OpenAI APIç›´æ¥å‘¼ã³å‡ºã—ã§ãƒãƒ£ãƒƒãƒˆè£œå®Œï¼ˆLangChainä»£æ›¿ï¼‰
    """
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}"

def create_conversation_messages(system_prompt, conversation_history, user_input):
    """
    ä¼šè©±å±¥æ­´ã‹ã‚‰ OpenAI APIç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã‚’ä½œæˆ
    """
    messages = [
        {"role": "system", "content": system_prompt}
    ]
    
    # ä¼šè©±å±¥æ­´ã‚’è¿½åŠ 
    for msg in conversation_history:
        if hasattr(msg, 'content'):
            role = "assistant" if hasattr(msg, 'type') and msg.type == "ai" else "user"
            messages.append({"role": role, "content": msg.content})
    
    # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’è¿½åŠ 
    messages.append({"role": "user", "content": user_input})
    
    return messages