import streamlit as st
import os
import time
from time import sleep
from pathlib import Path
from streamlit.components.v1 import html
from langchain.memory import ConversationSummaryBufferMemory
from langchain.chains import ConversationChain
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain.schema import SystemMessage
from openai import OpenAI
from langchain_openai import ChatOpenAI
# Streamlit Cloudå¯¾å¿œï¼špython-dotenvã®ä»£ã‚ã‚Šã«Streamlit Secretsã‚’ä½¿ç”¨
try:
    from dotenv import load_dotenv
    DOTENV_AVAILABLE = True
except ImportError:
    DOTENV_AVAILABLE = False
import functions as ft
import constants as ct

# Pydanticäº’æ›æ€§ã®å•é¡Œã‚’è§£æ±º
try:
    # ChatOpenAIã‚¯ãƒ©ã‚¹ã®ãƒ¢ãƒ‡ãƒ«å†æ§‹ç¯‰ã‚’å¼·åˆ¶å®Ÿè¡Œ
    from langchain_core.language_models.base import BaseLanguageModel
    ChatOpenAI.model_rebuild()
except Exception as e:
    print(f"Warning: ChatOpenAI model rebuild failed: {e}")
    # ç¶™ç¶šã—ã¦å®Ÿè¡Œ


# å„ç¨®è¨­å®š
# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ˜ç¤ºçš„ã«èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®ã¿ï¼‰
if DOTENV_AVAILABLE:
    env_path = Path('.') / '.env'
    load_dotenv(dotenv_path=env_path, override=True)

# API key ã®è¨­å®šï¼ˆStreamlit Cloud + ãƒ­ãƒ¼ã‚«ãƒ«å¯¾å¿œï¼‰
def get_openai_api_key():
    # 1. Streamlit Secrets
    try:
        if hasattr(st, 'secrets') and 'OPENAI_API_KEY' in st.secrets:
            return st.secrets['OPENAI_API_KEY']
    except Exception:
        pass
    
    # 2. ç’°å¢ƒå¤‰æ•°
    if "OPENAI_API_KEY" in os.environ:
        return os.environ["OPENAI_API_KEY"]
    
    # 3. .envãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨ï¼‰
    if DOTENV_AVAILABLE:
        env_file = Path(".env")
        if env_file.exists():
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line.startswith('OPENAI_API_KEY=') and not line.startswith('#'):
                        key_value = line.split('=', 1)
                        if len(key_value) == 2:
                            return key_value[1].strip('"\'')
    
    return None

# OpenAI API key ã®è¨­å®š
api_key = get_openai_api_key()
if api_key:
    os.environ['OPENAI_API_KEY'] = api_key

st.set_page_config(
    page_title=ct.APP_NAME
)

# ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
st.markdown(f"## {ct.APP_NAME}")

# åˆæœŸå‡¦ç†
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.start_flg = False
    st.session_state.pre_mode = ""
    st.session_state.shadowing_flg = False
    st.session_state.shadowing_button_flg = False
    st.session_state.shadowing_count = 0
    st.session_state.shadowing_first_flg = True
    st.session_state.shadowing_audio_input_flg = False
    st.session_state.shadowing_evaluation_first_flg = True
    st.session_state.dictation_flg = False
    st.session_state.dictation_button_flg = False
    st.session_state.dictation_count = 0
    st.session_state.dictation_first_flg = True
    st.session_state.dictation_chat_message = ""
    st.session_state.dictation_evaluation_first_flg = True
    st.session_state.chat_open_flg = False
    st.session_state.problem = ""
    st.session_state.audio_ready = False
    st.session_state.current_audio_file = None
    
    # OpenAIé–¢é€£ã®åˆæœŸåŒ–ã‚‚ä¸€åº¦ã ã‘å®Ÿè¡Œ

# OpenAI API ã¨LangChainã®åˆæœŸåŒ–ï¼ˆå¿…è¦æ™‚ã®ã¿ï¼‰
if "chain_basic_conversation" not in st.session_state:
    st.info("ğŸ”„ OpenAI APIã¨LangChainã‚’åˆæœŸåŒ–ä¸­...")
    
    # OpenAI APIã‚­ãƒ¼ã®å–å¾—ï¼ˆè¤‡æ•°ã®æ–¹æ³•ã‚’è©¦è¡Œï¼‰
    api_key = None
    
    # æ–¹æ³•1: ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ç›´æ¥å–å¾—
    api_key = os.environ.get("OPENAI_API_KEY")
    
    # æ–¹æ³•2: .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ‰‹å‹•èª­ã¿è¾¼ã¿
    if not api_key:
        env_file = Path(".env")
        if env_file.exists():
            try:
                with open(env_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith('OPENAI_API_KEY=') and not line.startswith('#'):
                            key_value = line.split('=', 1)
                            if len(key_value) == 2:
                                api_key = key_value[1].strip('"\'')
                                os.environ['OPENAI_API_KEY'] = api_key
                                break
            except Exception as e:
                st.warning(f".envãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # æ–¹æ³•3: Streamlit secretsã‹ã‚‰å–å¾—
    if not api_key:
        try:
            if hasattr(st, 'secrets') and "OPENAI_API_KEY" in st.secrets:
                api_key = st.secrets["OPENAI_API_KEY"]
        except Exception:
            pass
    
    # APIã‚­ãƒ¼ã®æ¤œè¨¼
    if not api_key or api_key == "your-openai-api-key-here" or len(api_key) < 20:
        st.error("ğŸ”‘ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.info("""
        **APIã‚­ãƒ¼ã®è¨­å®šæ–¹æ³•:**
        1. OpenAIã®Webã‚µã‚¤ãƒˆ (https://platform.openai.com/account/api-keys) ã§APIã‚­ãƒ¼ã‚’å–å¾—
        2. ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®æ–¹æ³•ã§è¨­å®š:
           - ç’°å¢ƒå¤‰æ•°: `OPENAI_API_KEY=your_key`
           - `.streamlit/secrets.toml` ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ 
        """)
        st.stop()
    
    try:
        st.session_state.openai_obj = OpenAI(api_key=api_key)
        
        # ChatOpenAIã®åˆæœŸåŒ– - æ®µéšçš„ã«ç•°ãªã‚‹æ–¹æ³•ã‚’è©¦è¡Œ
        llm_initialized = False
        
        # æ–¹æ³•1: åŸºæœ¬çš„ãªåˆæœŸåŒ–
        if not llm_initialized:
            try:
                st.session_state.llm = ChatOpenAI(
                    api_key=api_key,
                    model="gpt-4o-mini",
                    temperature=0.5
                )
                llm_initialized = True
                st.success("âœ… ChatOpenAIåˆæœŸåŒ–æˆåŠŸï¼ˆæ–¹æ³•1ï¼‰")
            except Exception as e1:
                st.warning(f"æ–¹æ³•1å¤±æ•—: {e1}")
        
        # æ–¹æ³•2: openai_api_keyãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        if not llm_initialized:
            try:
                st.session_state.llm = ChatOpenAI(
                    openai_api_key=api_key,
                    model="gpt-4o-mini",
                    temperature=0.5
                )
                llm_initialized = True
                st.success("âœ… ChatOpenAIåˆæœŸåŒ–æˆåŠŸï¼ˆæ–¹æ³•2ï¼‰")
            except Exception as e2:
                st.warning(f"æ–¹æ³•2å¤±æ•—: {e2}")
        
        # æ–¹æ³•3: ç’°å¢ƒå¤‰æ•°ã«ä¾å­˜ã™ã‚‹æ–¹æ³•
        if not llm_initialized:
            try:
                os.environ['OPENAI_API_KEY'] = api_key
                st.session_state.llm = ChatOpenAI(
                    model="gpt-4o-mini",
                    temperature=0.5
                )
                llm_initialized = True
                st.success("âœ… ChatOpenAIåˆæœŸåŒ–æˆåŠŸï¼ˆæ–¹æ³•3ï¼‰")
            except Exception as e3:
                st.warning(f"æ–¹æ³•3å¤±æ•—: {e3}")
        
        # æ–¹æ³•4: æ—§å½¢å¼ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã‚’ä½¿ç”¨
        if not llm_initialized:
            try:
                st.session_state.llm = ChatOpenAI(
                    openai_api_key=api_key,
                    model_name="gpt-4o-mini",
                    temperature=0.5
                )
                llm_initialized = True
                st.success("âœ… ChatOpenAIåˆæœŸåŒ–æˆåŠŸï¼ˆæ–¹æ³•4 - æ—§å½¢å¼ï¼‰")
            except Exception as e4:
                st.warning(f"æ–¹æ³•4å¤±æ•—: {e4}")
        
        if not llm_initialized:
            raise Exception("ã™ã¹ã¦ã®ChatOpenAIåˆæœŸåŒ–æ–¹æ³•ãŒå¤±æ•—ã—ã¾ã—ãŸ")
        
        # LangChainã®ãƒ¡ãƒ¢ãƒªã¨ãƒã‚§ãƒ¼ãƒ³ã‚’åˆæœŸåŒ–
        try:
            st.session_state.memory = ConversationSummaryBufferMemory(
                llm=st.session_state.llm,
                max_token_limit=1000,
                return_messages=True
            )

            # ãƒ¢ãƒ¼ãƒ‰ã€Œæ—¥å¸¸è‹±ä¼šè©±ã€ç”¨ã®Chainä½œæˆ
            st.session_state.chain_basic_conversation = ft.create_chain(ct.SYSTEM_TEMPLATE_BASIC_CONVERSATION)
            st.session_state.use_langchain = True
            st.success("âœ… LangChainãƒã‚§ãƒ¼ãƒ³åˆæœŸåŒ–æˆåŠŸ")
            
        except Exception as chain_error:
            st.warning(f"âš ï¸ LangChainãƒã‚§ãƒ¼ãƒ³ä½œæˆå¤±æ•—ã€ç›´æ¥OpenAI APIä½¿ç”¨ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™: {chain_error}")
            st.session_state.use_langchain = False
            st.session_state.conversation_history = []  # ä»£æ›¿ã®ä¼šè©±å±¥æ­´ç®¡ç†
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒã‚§ãƒ¼ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
            class FallbackChain:
                def __init__(self, api_key):
                    self.api_key = api_key
                    self.client = ft.create_simple_openai_client(api_key)
                
                def predict(self, input):
                    try:
                        # ã‚·ãƒ³ãƒ—ãƒ«ãªä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                        system_prompt = """ã‚ãªãŸã¯å„ªã—ãè¦ªåˆ‡ãªè‹±ä¼šè©±è¬›å¸«ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‹±èªã«å¯¾ã—ã¦è‡ªç„¶ã§é©åˆ‡ãªè¿”ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚
è‹±èªã§è¿”ç­”ã—ã€ç™ºéŸ³ã—ã‚„ã™ã„æ–‡ç« ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"""
                        
                        messages = [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": input}
                        ]
                        
                        return ft.simple_chat_completion(self.client, messages)
                    except Exception as e:
                        return f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å¿œç­”ã®ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
            
            st.session_state.chain_basic_conversation = FallbackChain(api_key)
            st.info("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–å®Œäº†")
        
    except Exception as e:
        st.error(f"ğŸš¨ OpenAI APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        st.info("APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

# åˆæœŸè¡¨ç¤º
# col1, col2, col3, col4 = st.columns([1, 1, 1, 2])
# æå‡ºèª²é¡Œç”¨
col1, col2, col3, col4 = st.columns([2, 2, 3, 3])
with col1:
    if st.session_state.start_flg:
        st.button("é–‹å§‹", use_container_width=True, type="primary")
    else:
        st.session_state.start_flg = st.button("é–‹å§‹", use_container_width=True, type="primary")
with col2:
    st.session_state.speed = st.selectbox(label="å†ç”Ÿé€Ÿåº¦", options=ct.PLAY_SPEED_OPTION, index=3, label_visibility="collapsed")
with col3:
    st.session_state.mode = st.selectbox(label="ãƒ¢ãƒ¼ãƒ‰", options=[ct.MODE_1, ct.MODE_2, ct.MODE_3], label_visibility="collapsed")
    # ãƒ¢ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã—ãŸéš›ã®å‡¦ç†
    if st.session_state.mode != st.session_state.pre_mode:
        # è‡ªå‹•ã§ãã®ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹
        st.session_state.start_flg = False
        # ã€Œæ—¥å¸¸è‹±ä¼šè©±ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        if st.session_state.mode == ct.MODE_1:
            st.session_state.dictation_flg = False
            st.session_state.shadowing_flg = False
        # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        st.session_state.shadowing_count = 0
        if st.session_state.mode == ct.MODE_2:
            st.session_state.dictation_flg = False
        # ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        st.session_state.dictation_count = 0
        if st.session_state.mode == ct.MODE_3:
            st.session_state.shadowing_flg = False
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ã‚’éè¡¨ç¤ºã«ã™ã‚‹
        st.session_state.chat_open_flg = False
    st.session_state.pre_mode = st.session_state.mode
with col4:
    st.session_state.englv = st.selectbox(label="è‹±èªãƒ¬ãƒ™ãƒ«", options=ct.ENGLISH_LEVEL_OPTION, label_visibility="collapsed")

with st.chat_message("assistant", avatar="images/ai_icon.jpg"):
    st.markdown("ã“ã¡ã‚‰ã¯ç”ŸæˆAIã«ã‚ˆã‚‹éŸ³å£°è‹±ä¼šè©±ã®ç·´ç¿’ã‚¢ãƒ—ãƒªã§ã™ã€‚ä½•åº¦ã‚‚ç¹°ã‚Šè¿”ã—ç·´ç¿’ã—ã€è‹±èªåŠ›ã‚’ã‚¢ãƒƒãƒ—ã•ã›ã¾ã—ã‚‡ã†ã€‚")
    st.markdown("**ã€æ“ä½œèª¬æ˜ã€‘**")
    st.success("""
    - ãƒ¢ãƒ¼ãƒ‰ã¨å†ç”Ÿé€Ÿåº¦ã‚’é¸æŠã—ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è‹±ä¼šè©±ã‚’å§‹ã‚ã¾ã—ã‚‡ã†ã€‚
    - ãƒ¢ãƒ¼ãƒ‰ã¯ã€Œæ—¥å¸¸è‹±ä¼šè©±ã€ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‹ã‚‰é¸ã¹ã¾ã™ã€‚
    - ç™ºè©±å¾Œã€5ç§’é–“æ²ˆé»™ã™ã‚‹ã“ã¨ã§éŸ³å£°å…¥åŠ›ãŒå®Œäº†ã—ã¾ã™ã€‚
    - ã€Œä¸€æ™‚ä¸­æ–­ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã“ã¨ã§ã€è‹±ä¼šè©±ã‚’ä¸€æ™‚ä¸­æ–­ã§ãã¾ã™ã€‚
    """)
    
    # æ—¥å¸¸è‹±ä¼šè©±ãƒ¢ãƒ¼ãƒ‰å°‚ç”¨ã®éŸ³å£°ãƒ˜ãƒ«ãƒ—ã‚’å¸¸æ™‚è¡¨ç¤º
    if st.session_state.mode == ct.MODE_1:
        with st.expander("ğŸ”§ éŸ³å£°ãŒèã“ãˆãªã„å ´åˆï¼ˆæ—¥å¸¸è‹±ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ï¼‰"):
            st.markdown("""
            **ãƒ–ãƒ©ã‚¦ã‚¶ã®è‡ªå‹•å†ç”ŸãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™:**
            1. AIå›ç­”ã®éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã§ â–¶ï¸ ãƒœã‚¿ãƒ³ã‚’æ‰‹å‹•ã§ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„
            2. ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§éŸ³å£°è‡ªå‹•å†ç”Ÿã‚’è¨±å¯ã—ã¦ãã ã•ã„
            3. éŸ³é‡è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„
            
            **Chrome/Edge:** è¨­å®š â†’ ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ â†’ ã‚µã‚¤ãƒˆã®è¨­å®š â†’ éŸ³å£°
            **Firefox:** è¨­å®š â†’ ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ â†’ è¨±å¯è¨­å®š â†’ è‡ªå‹•å†ç”Ÿ
            """)
st.divider()

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®ä¸€è¦§è¡¨ç¤º
for message in st.session_state.messages:
    if message["role"] == "assistant":
        with st.chat_message(message["role"], avatar="images/ai_icon.jpg"):
            st.markdown(message["content"])
    elif message["role"] == "user":
        with st.chat_message(message["role"], avatar="images/user_icon.jpg"):
            st.markdown(message["content"])
    else:
        st.divider()

# LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ä¸‹éƒ¨ã«ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œã®ãƒœã‚¿ãƒ³è¡¨ç¤º
if st.session_state.shadowing_flg:
    st.session_state.shadowing_button_flg = st.button("ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°é–‹å§‹")
if st.session_state.dictation_flg:
    st.session_state.dictation_button_flg = st.button("ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")

# ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ¢ãƒ¼ãƒ‰ã®ãƒãƒ£ãƒƒãƒˆå…¥åŠ›å—ä»˜æ™‚ã«å®Ÿè¡Œ
if st.session_state.chat_open_flg:
    # éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã‚’è¡¨ç¤ºï¼ˆst.rerun()ã®å½±éŸ¿ã‚’å—ã‘ãªã„å ´æ‰€ï¼‰
    ft.display_audio_player()
    st.info("AIãŒèª­ã¿ä¸Šã’ãŸéŸ³å£°ã‚’ã€ç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆæ¬„ã‹ã‚‰ãã®ã¾ã¾å…¥åŠ›ãƒ»é€ä¿¡ã—ã¦ãã ã•ã„ã€‚")

st.session_state.dictation_chat_message = st.chat_input("â€»ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€é¸æŠæ™‚ä»¥å¤–ã¯é€ä¿¡ä¸å¯")

if st.session_state.dictation_chat_message and not st.session_state.chat_open_flg:
    st.stop()

# ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
if st.session_state.start_flg:

    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€
    # ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ãƒãƒ£ãƒƒãƒˆé€ä¿¡æ™‚
    if st.session_state.mode == ct.MODE_3 and (st.session_state.dictation_button_flg or st.session_state.dictation_count == 0 or st.session_state.dictation_chat_message):
        if st.session_state.dictation_first_flg:
            st.session_state.chain_create_problem = ft.create_chain(ct.SYSTEM_TEMPLATE_CREATE_PROBLEM)
            st.session_state.dictation_first_flg = False
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ä»¥å¤–
        if not st.session_state.chat_open_flg:
            with st.spinner('å•é¡Œæ–‡ç”Ÿæˆä¸­...'):
                st.session_state.problem, llm_response_audio = ft.create_problem_and_play_audio()

            st.session_state.chat_open_flg = True
            st.session_state.dictation_flg = False
            st.rerun()
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ™‚ã®å‡¦ç†
        else:
            # ãƒãƒ£ãƒƒãƒˆæ¬„ã‹ã‚‰å…¥åŠ›ã•ã‚ŒãŸå ´åˆã«ã®ã¿è©•ä¾¡å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
            if not st.session_state.dictation_chat_message:
                st.stop()
            
            # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(st.session_state.problem)
            with st.chat_message("user", avatar=ct.USER_ICON_PATH):
                st.markdown(st.session_state.dictation_chat_message)

            # LLMãŒç”Ÿæˆã—ãŸå•é¡Œæ–‡ã¨ãƒãƒ£ãƒƒãƒˆå…¥åŠ›å€¤ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": st.session_state.problem})
            st.session_state.messages.append({"role": "user", "content": st.session_state.dictation_chat_message})
            
            with st.spinner('è©•ä¾¡çµæœã®ç”Ÿæˆä¸­...'):
                system_template = ct.SYSTEM_TEMPLATE_EVALUATION.format(
                    llm_text=st.session_state.problem,
                    user_text=st.session_state.dictation_chat_message
                )
                st.session_state.chain_evaluation = ft.create_chain(system_template)
                # å•é¡Œæ–‡ã¨å›ç­”ã‚’æ¯”è¼ƒã—ã€è©•ä¾¡çµæœã®ç”Ÿæˆã‚’æŒ‡ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
                llm_response_evaluation = ft.create_evaluation()
            
            # è©•ä¾¡çµæœã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ ã¨è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(llm_response_evaluation)
            st.session_state.messages.append({"role": "assistant", "content": llm_response_evaluation})
            st.session_state.messages.append({"role": "other"})
            
            # å„ç¨®ãƒ•ãƒ©ã‚°ã®æ›´æ–°
            st.session_state.dictation_flg = True
            st.session_state.dictation_chat_message = ""
            st.session_state.dictation_count += 1
            st.session_state.chat_open_flg = False

            st.rerun()

    
    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œæ—¥å¸¸è‹±ä¼šè©±ã€
    if st.session_state.mode == ct.MODE_1:
        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        
        if ft.record_audio(audio_input_file_path):
            # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
                transcript = ft.transcribe_audio(audio_input_file_path)
                audio_input_text = transcript.text

            # éŸ³å£°å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ç”»é¢è¡¨ç¤º
            with st.chat_message("user", avatar=ct.USER_ICON_PATH):
                st.markdown(audio_input_text)

            with st.spinner("ğŸ¤– AIå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã‚’LLMã«æ¸¡ã—ã¦å›ç­”å–å¾—
                llm_response = st.session_state.chain_basic_conversation.predict(input=audio_input_text)
            
            with st.spinner("ğŸ¤ éŸ³å£°ã‚’ç”Ÿæˆä¸­..."):
                # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
                llm_response_audio = st.session_state.openai_obj.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=llm_response
            )

            # mp3å½¢å¼ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.mp3"
            actual_file_path = ft.save_to_wav(llm_response_audio.content, audio_output_file_path)

            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’ï¼ˆæ—¥å¸¸è‹±ä¼šè©±ãƒ¢ãƒ¼ãƒ‰å°‚ç”¨è‡ªå‹•å†ç”Ÿï¼‰
            ft.play_wav_auto_for_conversation(actual_file_path, speed=st.session_state.speed)

            # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤ºã¨ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ 
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(llm_response)

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã¨LLMã‹ã‚‰ã®å›ç­”ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¸€è¦§ã«è¿½åŠ 
            st.session_state.messages.append({"role": "user", "content": audio_input_text})
            st.session_state.messages.append({"role": "assistant", "content": llm_response})


    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€
    # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚
    if st.session_state.mode == ct.MODE_2 and (st.session_state.shadowing_button_flg or st.session_state.shadowing_count == 0 or st.session_state.shadowing_audio_input_flg):
        if st.session_state.shadowing_first_flg:
            st.session_state.chain_create_problem = ft.create_chain(ct.SYSTEM_TEMPLATE_CREATE_PROBLEM)
            st.session_state.shadowing_first_flg = False
        
        if not st.session_state.shadowing_audio_input_flg:
            with st.spinner('å•é¡Œæ–‡ç”Ÿæˆä¸­...'):
                st.session_state.problem, llm_response_audio = ft.create_problem_and_play_audio_for_shadowing()

        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        st.session_state.shadowing_audio_input_flg = True
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        
        if ft.record_audio_for_shadowing(audio_input_file_path):
            st.session_state.shadowing_audio_input_flg = False

            with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
                # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                transcript = ft.transcribe_audio(audio_input_file_path)
                audio_input_text = transcript.text

            # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(st.session_state.problem)
            with st.chat_message("user", avatar=ct.USER_ICON_PATH):
                st.markdown(audio_input_text)
            
            # LLMãŒç”Ÿæˆã—ãŸå•é¡Œæ–‡ã¨éŸ³å£°å…¥åŠ›å€¤ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": st.session_state.problem})
            st.session_state.messages.append({"role": "user", "content": audio_input_text})

            with st.spinner('è©•ä¾¡çµæœã®ç”Ÿæˆä¸­...'):
                if st.session_state.shadowing_evaluation_first_flg:
                    system_template = ct.SYSTEM_TEMPLATE_EVALUATION.format(
                        llm_text=st.session_state.problem,
                        user_text=audio_input_text
                    )
                    st.session_state.chain_evaluation = ft.create_chain(system_template)
                    st.session_state.shadowing_evaluation_first_flg = False
                # å•é¡Œæ–‡ã¨å›ç­”ã‚’æ¯”è¼ƒã—ã€è©•ä¾¡çµæœã®ç”Ÿæˆã‚’æŒ‡ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
                llm_response_evaluation = ft.create_evaluation()
            
            # è©•ä¾¡çµæœã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ ã¨è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(llm_response_evaluation)
            st.session_state.messages.append({"role": "assistant", "content": llm_response_evaluation})
            st.session_state.messages.append({"role": "other"})
            
            # å„ç¨®ãƒ•ãƒ©ã‚°ã®æ›´æ–°
            st.session_state.shadowing_flg = True
            st.session_state.shadowing_count += 1

        # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã«å†æç”»
        st.rerun()